{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pymrio\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import country_converter as coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the storing folder for Exiobase3 data\n",
    "exio3_folder = 'C:/Users/danie/Nextcloud/Coding/Masterthesis/exiobase'\n",
    "download_folder = os.path.join(exio3_folder, 'exio_download')\n",
    "\n",
    "# Check if the exio_download folder exists, create if not\n",
    "if not os.path.exists(download_folder):\n",
    "    os.makedirs(download_folder)\n",
    "    print(f\"Created directory: {download_folder}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {download_folder}\")\n",
    "\n",
    "# Download Exiobase3 data to the specified folder\n",
    "exio_downloadlog = pymrio.download_exiobase3(storage_folder=download_folder, system=\"ixi\", years=[2018, 2019, 2020, 2021, 2022])\n",
    "print(exio_downloadlog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Exiobase3 (2021) data\n",
    "exio3 = pymrio.parse_exiobase3(path='C:/Users/danie/Nextcloud/Coding/Masterthesis/exiobase/exio_download/IOT_2021_ixi.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess meta data\n",
    "print(exio3.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for geographical sampling differences between FIGARO and EXIOBASE 3 ###\n",
    "\n",
    "# FIGARO countries\n",
    "figaro_countries = [\n",
    "    'AR', 'AT', 'AU', 'BE', 'BG', 'BR', 'CA', 'CH', 'CN', 'CY', 'CZ', 'DE', 'DK', 'EE', 'ES', 'FI', 'FIGW1', 'FR', 'GB',\n",
    "    'GR', 'HR', 'HU', 'ID', 'IE', 'IN', 'IT', 'JP', 'KR', 'LT', 'LU', 'LV', 'MT', 'MX', 'NL', 'NO', 'PL', 'PT', 'RO', 'RU',\n",
    "    'SA', 'SE', 'SI', 'SK', 'TR', 'US', 'ZA'\n",
    "]\n",
    "\n",
    "# Extract country codes from EXIOBASE 3 dataset\n",
    "exio_countries = exio3.get_regions()\n",
    "\n",
    "# Compare country codes\n",
    "common_countries = sorted(set(figaro_countries).intersection(exio_countries))\n",
    "figaro_only_countries = sorted(set(figaro_countries) - set(exio_countries))\n",
    "exio_only_countries = sorted(set(exio_countries) - set(figaro_countries))\n",
    "\n",
    "print(\"Common countries:\", common_countries)\n",
    "print(\"Countries only in FIGARO:\", figaro_only_countries)\n",
    "print(\"Countries only in EXIOBASE 3:\", exio_only_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argentina and Saudi Arabia are not in EXIOBASE 3, but in FIGARO\n",
    "# Taiwan is in EXIOBASE 3, but not in FIGARO\n",
    "# FIGW1 is ROW in Figaro\n",
    "# WA (Asia), WE (Europe), WF (Africa), WL (Latin America), WM (Middle East), WP (Pacific) are ROW regions in Exiobase3\n",
    "\n",
    "# Collect all RoW regions and Taiwan in one FIGARO region\n",
    "exio3.rename_regions({'WA': 'FIGW1', 'WE': 'FIGW1', 'WF': 'FIGW1', 'WL': 'FIGW1', 'WM': 'FIGW1', 'WP': 'FIGW1', 'TW': 'FIGW1'})\n",
    "\n",
    "# Aggregate EXIOBASE 3 data to FIGARO regions\n",
    "exio3.aggregate_duplicates(inplace=True)\n",
    "exio3.Z.to_csv('C:/Users/danie/Nextcloud/Coding/Masterthesis/exiobase/country_agg_exio3_figaro.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available classification data that contains possibly useful different names and aggregation levels\n",
    "mrio_class = pymrio.get_classification(mrio_name='exio3_ixi')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the full mrio_class\n",
    "display(mrio_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conversion dictionnary from ExioName to ExioLabel and check for correctness by displaying it\n",
    "conv_dict = mrio_class.get_sector_dict(mrio_class.sectors.ExioName, mrio_class.sectors.ExioLabel)\n",
    "display(conv_dict)\n",
    "\n",
    "# Rename sectors in the pymrio object\n",
    "exio3.rename_sectors(conv_dict)\n",
    "\n",
    "# Check if the renaming was successful\n",
    "print(exio3.Z.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aggregate Exiobase3 data ###\n",
    "# Done through renaming, which also helps to adapt it to eurostat data\n",
    "\n",
    "# Renaming of sectors requires mappping of ExioLabel to NACE classification\n",
    "\n",
    "rename_dict_exio3_NACE = {\n",
    "    \"A_PARI\": \"A01\",\n",
    "    \"A_WHEA\": \"A01\",\n",
    "    \"A_OCER\": \"A01\",\n",
    "    \"A_FVEG\": \"A01\",\n",
    "    \"A_OILS\": \"A01\",\n",
    "    \"A_SUGB\": \"A01\",\n",
    "    \"A_FIBR\": \"A01\",\n",
    "    \"A_OTCR\": \"A01\",\n",
    "    \"A_CATL\": \"A01\",\n",
    "    \"A_PIGS\": \"A01\",\n",
    "    \"A_PLTR\": \"A01\",\n",
    "    \"A_OMEA\": \"A01\",\n",
    "    \"A_OANP\": \"A01\",\n",
    "    \"A_MILK\": \"A01\",\n",
    "    \"A_WOOL\": \"A01\",\n",
    "    \"A_MANC\": \"A01\",\n",
    "    \"A_MANB\": \"A01\",\n",
    "    \"A_FORE\": \"A02\",\n",
    "    \"A_FISH\": \"A03\",\n",
    "    \"A_GASE\": \"B_gas\",\n",
    "    \"A_OGPL\": \"B_gas\",\n",
    "    \"A_COAL\": \"B_nongas\",\n",
    "    \"A_COIL\": \"B_nongas\",\n",
    "    \"A_ORAN\": \"B_nongas\",\n",
    "    \"A_IRON\": \"B_nongas\",\n",
    "    \"A_COPO\": \"B_nongas\",\n",
    "    \"A_NIKO\": \"B_nongas\",\n",
    "    \"A_ALUO\": \"B_nongas\",\n",
    "    \"A_PREO\": \"B_nongas\",\n",
    "    \"A_LZTO\": \"B_nongas\",\n",
    "    \"A_ONFO\": \"B_nongas\",\n",
    "    \"A_STON\": \"B_nongas\",\n",
    "    \"A_SDCL\": \"B_nongas\",\n",
    "    \"A_CHMF\": \"B_nongas\",\n",
    "    \"A_PCAT\": \"C10-12\",\n",
    "    \"A_PPIG\": \"C10-12\",\n",
    "    \"A_PPLT\": \"C10-12\",\n",
    "    \"A_POME\": \"C10-12\",\n",
    "    \"A_VOIL\": \"C10-12\",\n",
    "    \"A_DAIR\": \"C10-12\",\n",
    "    \"A_RICE\": \"C10-12\",\n",
    "    \"A_SUGR\": \"C10-12\",\n",
    "    \"A_OFOD\": \"C10-12\",\n",
    "    \"A_BEVR\": \"C10-12\",\n",
    "    \"A_FSHP\": \"C10-12\",\n",
    "    \"A_TOBC\": \"C10-12\",\n",
    "    \"A_TEXT\": \"C13-15\",\n",
    "    \"A_GARM\": \"C13-15\",\n",
    "    \"A_LETH\": \"C13-15\",\n",
    "    \"A_WOOD\": \"C16\",\n",
    "    \"A_WOOW\": \"C16\",\n",
    "    \"A_PULP\": \"C17\",\n",
    "    \"A_PAPR\": \"C17\",\n",
    "    \"A_PAPE\": \"C17\",\n",
    "    \"A_MDIA\": \"C18\",\n",
    "    \"A_COKE\": \"C19\",\n",
    "    \"A_REFN\": \"C19\",\n",
    "    \"A_PLAS\": \"C20-21\",\n",
    "    \"A_PLAW\": \"C20-21\",\n",
    "    \"A_NFER\": \"C20-21\",\n",
    "    \"A_PFER\": \"C20-21\",\n",
    "    \"A_CHEM\": \"C20-21\",\n",
    "    \"A_RUBP\": \"C22\",\n",
    "    \"A_GLAS\": \"C23\",\n",
    "    \"A_GLAW\": \"C23\",\n",
    "    \"A_CRMC\": \"C23\",\n",
    "    \"A_BRIK\": \"C23\",\n",
    "    \"A_CMNT\": \"C23\",\n",
    "    \"A_ASHW\": \"C23\",\n",
    "    \"A_ONMM\": \"C23\",\n",
    "    \"A_NUCF\": \"C24\",\n",
    "    \"A_STEL\": \"C24\",\n",
    "    \"A_STEW\": \"C24\",\n",
    "    \"A_PREM\": \"C24\",\n",
    "    \"A_PREW\": \"C24\",\n",
    "    \"A_ALUM\": \"C24\",\n",
    "    \"A_ALUW\": \"C24\",\n",
    "    \"A_LZTP\": \"C24\",\n",
    "    \"A_LZTW\": \"C24\",\n",
    "    \"A_COPP\": \"C24\",\n",
    "    \"A_COPW\": \"C24\",\n",
    "    \"A_ONFM\": \"C24\",\n",
    "    \"A_ONFW\": \"C24\",\n",
    "    \"A_METC\": \"C24\",\n",
    "    \"A_FABM\": \"C25_33\",\n",
    "    \"A_MACH\": \"C25\",\n",
    "    \"A_OFMA\": \"C26\",\n",
    "    \"A_ELMA\": \"C27\",\n",
    "    \"A_RATV\": \"C27\",\n",
    "    \"A_MEIN\": \"C28_32\",\n",
    "    \"A_MOTO\": \"C29\",\n",
    "    \"A_OTRE\": \"C30\",\n",
    "    \"A_FURN\": \"C31\",\n",
    "    \"A_POWC\": \"D35\",\n",
    "    \"A_POWG\": \"D35\",\n",
    "    \"A_POWN\": \"D35\",\n",
    "    \"A_POWH\": \"D35\",\n",
    "    \"A_POWW\": \"D35\",\n",
    "    \"A_POWP\": \"D35\",\n",
    "    \"A_POWB\": \"D35\",\n",
    "    \"A_POWS\": \"D35\",\n",
    "    \"A_POWE\": \"D35\",\n",
    "    \"A_POWO\": \"D35\",\n",
    "    \"A_POWM\": \"D35\",\n",
    "    \"A_POWZ\": \"D35\",\n",
    "    \"A_POWT\": \"D35\",\n",
    "    \"A_POWD\": \"D35\",\n",
    "    \"A_GASD\": \"D35\",\n",
    "    \"A_HWAT\": \"D35\",\n",
    "    \"A_WATR\": \"E36\",\n",
    "    \"A_RYMS\": \"E37-39\",\n",
    "    \"A_BOTW\": \"E37-39\",\n",
    "    \"A_INCF\": \"E37-39\",\n",
    "    \"A_INCP\": \"E37-39\",\n",
    "    \"A_INCL\": \"E37-39\",\n",
    "    \"A_INCM\": \"E37-39\",\n",
    "    \"A_INCT\": \"E37-39\",\n",
    "    \"A_INCW\": \"E37-39\",\n",
    "    \"A_INCO\": \"E37-39\",\n",
    "    \"A_BIOF\": \"E37-39\",\n",
    "    \"A_BIOP\": \"E37-39\",\n",
    "    \"A_BIOS\": \"E37-39\",\n",
    "    \"A_COMF\": \"E37-39\",\n",
    "    \"A_COMW\": \"E37-39\",\n",
    "    \"A_WASF\": \"E37-39\",\n",
    "    \"A_WASO\": \"E37-39\",\n",
    "    \"A_LANF\": \"E37-39\",\n",
    "    \"A_LANP\": \"E37-39\",\n",
    "    \"A_LANL\": \"E37-39\",\n",
    "    \"A_LANI\": \"E37-39\",\n",
    "    \"A_LANT\": \"E37-39\",\n",
    "    \"A_LANW\": \"E37-39\",\n",
    "    \"A_CONS\": \"F\",\n",
    "    \"A_CONW\": \"F\",\n",
    "    \"A_TDMO\": \"G45\",\n",
    "    \"A_TDWH\": \"G46\",\n",
    "    \"A_TDFU\": \"G47\",\n",
    "    \"A_TDRT\": \"G47\",\n",
    "    \"A_TRAI\": \"H49\",\n",
    "    \"A_TLND\": \"H49\",\n",
    "    \"A_TPIP\": \"H49\",\n",
    "    \"A_TWAS\": \"H50\",\n",
    "    \"A_TWAI\": \"H50\",\n",
    "    \"A_TAIR\": \"H51\",\n",
    "    \"A_TAUX\": \"H52\",\n",
    "    \"A_PTEL\": \"H53\",\n",
    "    \"A_HORE\": \"I\",\n",
    "    \"A_COMP\": \"J62_63\",\n",
    "    \"A_FINT\": \"K64\",\n",
    "    \"A_FINS\": \"K65\",\n",
    "    \"A_FAUX\": \"K66\",\n",
    "    \"A_REAL\": \"L68\",\n",
    "    \"A_RESD\": \"M_N\",\n",
    "    \"A_OBUS\": \"M_N\",\n",
    "    \"A_MARE\": \"M_N\",\n",
    "    \"A_PADF\": \"O84\",\n",
    "    \"A_EDUC\": \"P85\",\n",
    "    \"A_HEAL\": \"Q\",\n",
    "    \"A_RECR\": \"R_S\",\n",
    "    \"A_ORGA\": \"R_S\",\n",
    "    \"A_OSER\": \"R_S\",\n",
    "    \"A_PRHH\": \"T\",\n",
    "    \"A_EXTO\": \"U\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mapping with the rename_sectors tool of pymrio\n",
    "exio3.rename_sectors(rename_dict_exio3_NACE)\n",
    "print(exio3.Z.index)\n",
    "\n",
    "# Aggregate duplicates\n",
    "exio3.aggregate_duplicates()\n",
    "print(exio3.Z)\n",
    "\n",
    "# Convert to df\n",
    "exio_Z_df = pd.DataFrame(exio3.Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(exio_Z_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction snippet of the energy outputs\n",
    "\n",
    "# Extract the energy matrix for B_gas and B_nongas\n",
    "energy_matrix = exio3.Z.loc[(slice(None), ['B_gas', 'B_nongas']), :]\n",
    "\n",
    "# Reorder the matrix according to the country\n",
    "energy_matrix = energy_matrix.sort_index(level=0)\n",
    "\n",
    "# Display the reordered energy matrix\n",
    "print(energy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the energy inputs for each sector and country\n",
    "energy_inputs = exio3.Z.loc[(slice(None), ['B_gas', 'B_nongas']), :]\n",
    "\n",
    "# Compute the total energy inputs by summing the gas and nongas inputs\n",
    "total_energy_inputs = energy_inputs.groupby(level=0).sum()\n",
    "\n",
    "# Calculate the share of gas and nongas in the total energy inputs\n",
    "energy_shares = energy_inputs.div(total_energy_inputs, level=0)\n",
    "\n",
    "# Sort the energy shares so that gas and nongas of each country are next to each other\n",
    "energy_shares = energy_shares.sort_index(level=0)\n",
    "\n",
    "# Convert energy_shares to a pandas DataFrame\n",
    "energy_shares_df = pd.DataFrame(energy_shares)\n",
    "\n",
    "# Display the energy shares DataFrame\n",
    "display(energy_shares_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# List of countries\n",
    "countries = energy_shares_df.index.get_level_values(0).unique().tolist()\n",
    "\n",
    "# List of covered sectors\n",
    "sectors = energy_shares_df.columns.get_level_values(1).unique().tolist()\n",
    "\n",
    "# Number of sectors per country\n",
    "sectors_per_country = energy_shares_df.groupby(level=0).size()\n",
    "\n",
    "# Number of countries\n",
    "num_countries = len(countries)\n",
    "\n",
    "# Number of sectors\n",
    "num_sectors = len(sectors)\n",
    "\n",
    "print(\"List of countries:\", countries)\n",
    "print(\"Number of countries:\", num_countries)\n",
    "print(\"List of covered sectors:\", sectors)\n",
    "print(\"Number of sectors:\", num_sectors)\n",
    "print(\"Number of sectors per country:\")\n",
    "print(sectors_per_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_index_to_multiindex(df):\n",
    "    \"\"\"\n",
    "    Split the index and columns of the DataFrame into a MultiIndex.\n",
    "    The index and columns are expected to have a structure like 'XX_sector_code'.\n",
    "    \"\"\"\n",
    "    def split_index(index):\n",
    "        return pd.MultiIndex.from_tuples([tuple(i.split('_', 1)) for i in index], names=['Country', 'Sector'])\n",
    "\n",
    "    df.index = split_index(df.index)\n",
    "    df.columns = split_index(df.columns)\n",
    "    return df\n",
    "\n",
    "def process_files_and_split_index(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all CSV files in the input folder, split the index and columns into a MultiIndex,\n",
    "    and save the new files in the specified output directory with a 'multiindex_' prefix.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "\n",
    "            df = pd.read_csv(file_path, index_col=0)\n",
    "            df = split_index_to_multiindex(df)\n",
    "\n",
    "            # Save the modified DataFrame to the output directory with 'multiindex_' prefix\n",
    "            output_file_path = os.path.join(output_dir, f'multiindex_{filename}')\n",
    "            df.to_csv(output_file_path)\n",
    "            print(f\"Processed and saved {filename} to {output_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_dir = 'C:/Users/danie/Nextcloud/Coding/Masterthesis/data/raw/figaro_tables'\n",
    "output_dir = 'C:/Users/danie/Nextcloud/Coding/Masterthesis/notebooks/NB_exio3_figaro_gas/figaro_multi_index'\n",
    "process_files_and_split_index(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for the 2021 multiindex figaro table\n",
    "file_path_2021 = os.path.join(output_dir, 'multiindex_2021_figaro_64.csv')\n",
    "\n",
    "# Load the 2021 multiindex figaro table\n",
    "df_2021 = pd.read_csv(file_path_2021, index_col=[0, 1], header=[0, 1])\n",
    "\n",
    "# Display the first few rows of the dataframe to verify\n",
    "print(df_2021.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 1. Sector Mapping (Renaming + Aggregation)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "sector_mapping = {\n",
    "    \"C10T12\": \"C10-12\",\n",
    "    \"C13T15\": \"C13-15\",\n",
    "    \"E37T39\": \"E37-39\",\n",
    "    \"J58\": \"J\", \"J59_60\": \"J\", \"J61\": \"J\", \"J62_63\": \"J\",\n",
    "    \"M69_70\": \"M_N\", \"M71\": \"M_N\", \"M72\": \"M_N\", \"M73\": \"M_N\", \"M74_75\": \"M_N\",\n",
    "    \"N77\": \"M_N\", \"N78\": \"M_N\", \"N79\": \"M_N\", \"N80T82\": \"M_N\",\n",
    "    \"Q86\": \"Q\", \"Q87_88\": \"Q\",\n",
    "    \"R90T92\": \"R_S\", \"R93\": \"R_S\", \"S94\": \"R_S\", \"S95\": \"R_S\", \"S96\": \"R_S\",\n",
    "    \"L\": \"L68\"\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Load FIGARO Data for 2021\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Define the file path for the 2021 multiindex figaro table\n",
    "file_path_2021 = os.path.join(output_dir, 'multiindex_2021_figaro_64.csv')\n",
    "\n",
    "# Load the 2021 multiindex figaro table\n",
    "df_2021 = pd.read_csv(file_path_2021, index_col=[0, 1], header=[0, 1])\n",
    "\n",
    "# Display the first few rows to verify structure\n",
    "print(df_2021.head())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Function to Apply Sector Mapping and Aggregate\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def apply_sector_mapping(df, sector_mapping):\n",
    "    \"\"\"\n",
    "    Rename and aggregate sectors in both rows and columns using the provided mapping.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Step 1: Rename Row Index (Industries)\n",
    "    new_row_index = [(country, sector_mapping.get(sector, sector)) for country, sector in df.index]\n",
    "    df.index = pd.MultiIndex.from_tuples(new_row_index, names=['Country', 'Sector'])\n",
    "\n",
    "    # ✅ Step 2: Rename Column Index (Industries)\n",
    "    new_col_index = [(country, sector_mapping.get(sector, sector)) for country, sector in df.columns]\n",
    "    df.columns = pd.MultiIndex.from_tuples(new_col_index, names=['Country', 'Sector'])\n",
    "\n",
    "    # ✅ Step 3: Aggregate Mapped Sectors\n",
    "    df = df.groupby(level=['Country', 'Sector']).sum()  # Aggregate rows\n",
    "    df = df.groupby(level=['Country', 'Sector'], axis=1).sum()  # Aggregate columns\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Apply Sector Mapping to FIGARO Data\n",
    "# ---------------------------------------------------\n",
    "\n",
    "df_2021_mapped = apply_sector_mapping(df_2021, sector_mapping)\n",
    "\n",
    "# Display the first few rows to verify the aggregation worked\n",
    "print(df_2021_mapped.head())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Add Gross Output Row\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def add_gross_output_row(df):\n",
    "    gross_output = df.sum(axis=0)\n",
    "    gross_output.name = ('GO', 'GO')\n",
    "    df = pd.concat([df, pd.DataFrame(gross_output).T])\n",
    "    return df\n",
    "\n",
    "df_2021_mapped = add_gross_output_row(df_2021_mapped)\n",
    "\n",
    "# Ensure the row indices have the same named index structure as the columns\n",
    "df_2021_mapped.index.names = df_2021_mapped.columns.names\n",
    "\n",
    "# Display the row index names\n",
    "print(\"Row index names:\", df_2021_mapped.index.names)\n",
    "\n",
    "# Display the column index names\n",
    "print(\"Column index names:\", df_2021_mapped.columns.names)\n",
    "\n",
    "# Display the row indices\n",
    "display(df_2021_mapped.index)\n",
    "\n",
    "# Display the first few rows to verify the Gross Output row was added\n",
    "print(df_2021_mapped.tail())\n",
    "df_2021_mapped.to_csv('C:/Users/danie/Nextcloud/Coding/Masterthesis/notebooks/NB_exio3_figaro_gas/figaro_mapped_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_countries(df, countries_to_merge, target='FIGW1'):\n",
    "    \"\"\"\n",
    "    Relabels rows and columns so that any country in countries_to_merge is replaced by target.\n",
    "    Then groups by the MultiIndex to sum the duplicated entries.\n",
    "    \n",
    "    Assumes both rows and columns are MultiIndex with levels ['Country', 'Sector'].\n",
    "    \n",
    "    Parameters:\n",
    "      df: pd.DataFrame with MultiIndex for both rows and columns\n",
    "      countries_to_merge: list of country codes to merge (e.g., ['AR', 'SA'])\n",
    "      target: the target country code to absorb the values (default 'FIGW1')\n",
    "      \n",
    "    Returns:\n",
    "      A DataFrame with the specified countries merged into the target.\n",
    "    \"\"\"\n",
    "    # Save the original index names (should be ['Country', 'Sector'])\n",
    "    row_index_names = df.index.names\n",
    "    col_index_names = df.columns.names\n",
    "    \n",
    "    # --- Relabel row index: Replace countries in countries_to_merge with target\n",
    "    new_row_index = [\n",
    "        (target if country in countries_to_merge else country, sector)\n",
    "        for country, sector in df.index\n",
    "    ]\n",
    "    df.index = pd.MultiIndex.from_tuples(new_row_index, names=row_index_names)\n",
    "    \n",
    "    # --- Relabel column index: Replace countries in countries_to_merge with target\n",
    "    new_col_index = [\n",
    "        (target if country in countries_to_merge else country, sector)\n",
    "        for country, sector in df.columns\n",
    "    ]\n",
    "    df.columns = pd.MultiIndex.from_tuples(new_col_index, names=col_index_names)\n",
    "    \n",
    "    # --- Group by the MultiIndex levels to aggregate duplicate entries (summing over duplicates)\n",
    "    df = df.groupby(level=row_index_names).sum()\n",
    "    df = df.groupby(axis=1, level=col_index_names).sum()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "merged_df = merge_countries(df_2021_mapped, ['AR', 'SA'])\n",
    "display(merged_df)\n",
    "\n",
    "merged_df.to_csv('C:/Users/danie/Nextcloud/Coding/Masterthesis/notebooks/NB_exio3_figaro_gas/figaro_mapped_2021_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- STEP 0: Extract the gross output row\n",
    "# The gross output row has both levels of the index equal to \"GO\"\n",
    "go_row = merged_df.loc[(\"GO\", \"GO\")]\n",
    "\n",
    "# ----- STEP 1: Build a dictionary for gross output for each supplier column\n",
    "# For each supplier column (e.g. (AT, A01)), retrieve its gross output from the GO row.\n",
    "gross_output = {}\n",
    "for col in merged_df.columns:\n",
    "    country, supplier_sector = col\n",
    "    if supplier_sector != \"GO\":  # Only for supplier columns\n",
    "        try:\n",
    "            # The gross output for column (country, supplier_sector) is in the GO row.\n",
    "            go_value = go_row[col]\n",
    "            gross_output[col] = go_value\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Gross output for supplier column {col} not found; defaulting to 1.\")\n",
    "            gross_output[col] = 1\n",
    "\n",
    "# ----- STEP 2: Create the interindustry block\n",
    "# Exclude rows and columns where the Sector is \"GO\"\n",
    "rows_mask = merged_df.index.get_level_values(\"Sector\") != \"GO\"\n",
    "cols_mask = merged_df.columns.get_level_values(\"Sector\") != \"GO\"\n",
    "interindustry_block = merged_df.loc[rows_mask, cols_mask]\n",
    "\n",
    "# ----- STEP 3: Compute the technical coefficients\n",
    "# For each supplier column, divide all its entries by its corresponding gross output.\n",
    "def normalize_column(col):\n",
    "    supplier_key = col.name  # a tuple (country, supplier_sector)\n",
    "    denominator = gross_output.get(supplier_key, 1)\n",
    "    return col / denominator\n",
    "\n",
    "tech_coeff = interindustry_block.apply(normalize_column, axis=0)\n",
    "\n",
    "# ----- STEP 4: Save or display the technical coefficients table\n",
    "tech_coeff.to_csv('technical_coefficients_from_merged.csv')\n",
    "print(\"Technical coefficients table saved to 'technical_coefficients_from_merged.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ----- STEP 0: Extract the gross output row (since it’s unique, with index (\"GO\",\"GO\"))\n",
    "go_row = merged_df.loc[(\"GO\", \"GO\")]\n",
    "\n",
    "# ----- STEP 1: Build a dictionary for gross output for each supplier column\n",
    "# For each supplier column (e.g. (AT, A01)), retrieve its gross output from the GO row.\n",
    "gross_output = {}\n",
    "for col in merged_df.columns:\n",
    "    country, supplier_sector = col\n",
    "    if supplier_sector != \"GO\":  # Only for supplier columns\n",
    "        try:\n",
    "            # Retrieve the gross output for this supplier column from the GO row.\n",
    "            go_value = go_row[col]\n",
    "            gross_output[col] = go_value\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Gross output for supplier column {col} not found; defaulting to 1.\")\n",
    "            gross_output[col] = 1\n",
    "\n",
    "# ----- STEP 2: Create the interindustry block by excluding rows and columns where Sector == \"GO\"\n",
    "rows_mask = merged_df.index.get_level_values(\"Sector\") != \"GO\"\n",
    "cols_mask = merged_df.columns.get_level_values(\"Sector\") != \"GO\"\n",
    "interindustry_block = merged_df.loc[rows_mask, cols_mask]\n",
    "\n",
    "# ----- STEP 3: Compute the technical coefficients\n",
    "def normalize_column(col):\n",
    "    supplier_key = col.name  # a tuple (country, supplier_sector)\n",
    "    denominator = gross_output.get(supplier_key, 1)\n",
    "    return col / denominator\n",
    "\n",
    "tech_coeff = interindustry_block.apply(normalize_column, axis=0)\n",
    "\n",
    "# ----- STEP 4: Duplicate B rows with new sector names \"B_gas\" and \"B_nongas\"\n",
    "# Select rows where Sector == \"B\"\n",
    "b_rows = tech_coeff.loc[tech_coeff.index.get_level_values(\"Sector\") == \"B\"].copy()\n",
    "\n",
    "# Create duplicates with new sector names\n",
    "def update_sector(index, new_label):\n",
    "    # index is a MultiIndex; we rebuild it with the second level replaced for rows where it is \"B\"\n",
    "    new_tuples = []\n",
    "    for country, sector in index:\n",
    "        if sector == \"B\":\n",
    "            new_tuples.append((country, new_label))\n",
    "        else:\n",
    "            new_tuples.append((country, sector))\n",
    "    return pd.MultiIndex.from_tuples(new_tuples, names=index.names)\n",
    "\n",
    "b_rows_gas = b_rows.copy()\n",
    "b_rows_nongas = b_rows.copy()\n",
    "b_rows_gas.index = update_sector(b_rows.index, \"B_gas\")\n",
    "b_rows_nongas.index = update_sector(b_rows.index, \"B_nongas\")\n",
    "\n",
    "# Remove the original B rows and append the duplicates\n",
    "non_b_rows = tech_coeff.loc[tech_coeff.index.get_level_values(\"Sector\") != \"B\"]\n",
    "tech_coeff_rows_modified = pd.concat([non_b_rows, b_rows_gas, b_rows_nongas]).sort_index()\n",
    "\n",
    "# ----- STEP 5: Duplicate B columns with new sector names \"B_gas\" and \"B_nongas\"\n",
    "# Columns are a MultiIndex. First, identify columns where the Sector level is \"B\".\n",
    "b_cols_mask = tech_coeff_rows_modified.columns.get_level_values(\"Sector\") == \"B\"\n",
    "b_cols = tech_coeff_rows_modified.columns[b_cols_mask]\n",
    "\n",
    "# Extract the B columns\n",
    "b_cols_df = tech_coeff_rows_modified.loc[:, b_cols].copy()\n",
    "\n",
    "# Create two copies with new column labels\n",
    "def update_column_labels(columns, new_label):\n",
    "    new_tuples = []\n",
    "    for country, sector in columns:\n",
    "        if sector == \"B\":\n",
    "            new_tuples.append((country, new_label))\n",
    "        else:\n",
    "            new_tuples.append((country, sector))\n",
    "    return pd.MultiIndex.from_tuples(new_tuples, names=columns.names)\n",
    "\n",
    "b_cols_gas = b_cols_df.copy()\n",
    "b_cols_nongas = b_cols_df.copy()\n",
    "b_cols_gas.columns = update_column_labels(b_cols_gas.columns, \"B_gas\")\n",
    "b_cols_nongas.columns = update_column_labels(b_cols_nongas.columns, \"B_nongas\")\n",
    "\n",
    "# Remove original B columns from the DataFrame\n",
    "non_b_cols_mask = tech_coeff_rows_modified.columns.get_level_values(\"Sector\") != \"B\"\n",
    "non_b_cols = tech_coeff_rows_modified.columns[non_b_cols_mask]\n",
    "tech_coeff_cols_modified = tech_coeff_rows_modified.loc[:, non_b_cols]\n",
    "\n",
    "# Concatenate the non-B columns with the new duplicates along axis=1\n",
    "final_df = pd.concat([tech_coeff_cols_modified, b_cols_gas, b_cols_nongas], axis=1)\n",
    "\n",
    "# Optionally, sort the columns (and rows) if desired:\n",
    "final_df = final_df.sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "# ----- STEP 6: Save the final modified table to CSV\n",
    "final_df.to_csv('technical_coefficients_modified.csv')\n",
    "print(\"Modified technical coefficients table saved to 'technical_coefficients_modified.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Save the energy shares DataFrame to a CSV file\n",
    "energy_shares_df.to_csv('C:/Users/danie/Nextcloud/Coding/Masterthesis/exiobase/energy_shares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def split_index_to_multiindex(df):\n",
    "    \"\"\"\n",
    "    Split the index and columns of the DataFrame into a MultiIndex.\n",
    "    The index and columns are expected to have a structure like 'XX_sector_code'.\n",
    "    \"\"\"\n",
    "    def split_index(index):\n",
    "        return pd.MultiIndex.from_tuples([tuple(i.split('_', 1)) for i in index], names=['Country', 'Sector'])\n",
    "\n",
    "    df.index = split_index(df.index)\n",
    "    df.columns = split_index(df.columns)\n",
    "    return df\n",
    "\n",
    "def process_files_and_split_index(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all CSV files in the input folder, split the index and columns into a MultiIndex,\n",
    "    and save the new files in the specified output directory with a 'multiindex_' prefix.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "\n",
    "            df = pd.read_csv(file_path, index_col=0)\n",
    "            df = split_index_to_multiindex(df)\n",
    "\n",
    "            # Save the modified DataFrame to the output directory with 'multiindex_' prefix\n",
    "            output_file_path = os.path.join(output_dir, f'multiindex_{filename}')\n",
    "            df.to_csv(output_file_path)\n",
    "            print(f\"Processed and saved {filename} to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Application for file paths\n",
    "input_dir = 'C:/Users/danie/Nextcloud/Coding/Masterthesis/data/raw/figaro_tables'\n",
    "output_dir = 'C:/Users/danie/Nextcloud/Coding/Masterthesis/notebooks/NB_exio3_figaro_gas/figaro_multi_index'\n",
    "process_files_and_split_index(input_dir, output_dir)\n",
    "# Define the file path for the 2021 multiindex figaro table\n",
    "file_path_2021 = os.path.join(output_dir, 'multiindex_2021_figaro_64.csv')\n",
    "\n",
    "# Load the 2021 multiindex figaro table\n",
    "df_2021 = pd.read_csv(file_path_2021, index_col=[0, 1], header=[0, 1])\n",
    "\n",
    "# Display the first few rows of the dataframe to verify\n",
    "print(df_2021.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 1. Sector Mapping (Renaming + Aggregation)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "sector_mapping = {\n",
    "    \"C10T12\": \"C10-12\",\n",
    "    \"C13T15\": \"C13-15\",\n",
    "    \"C31_32\": \"C31_32\",\n",
    "    \"E37T39\": \"E37-39\",\n",
    "    \"J58\": \"J\", \"J59_60\": \"J\", \"J61\": \"J\", \"J62_63\": \"J\",  # Aggregated\n",
    "    \"M69_70\": \"M_N\", \"M71\": \"M_N\", \"M72\": \"M_N\", \"M73\": \"M_N\", \"M74_75\": \"M_N\",\n",
    "    \"N77\": \"M_N\", \"N78\": \"M_N\", \"N79\": \"M_N\", \"N80T82\": \"M_N\",\n",
    "    \"Q86\": \"Q\", \"Q87_88\": \"Q\",\n",
    "    \"R90T92\": \"R_S\", \"R93\": \"R_S\", \"S94\": \"R_S\", \"S95\": \"R_S\", \"S96\": \"R_S\",\n",
    "    \"L\": \"L68\"\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Load FIGARO Data for 2021\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Define the file path for the 2021 multiindex figaro table\n",
    "file_path_2021 = os.path.join(output_dir, 'multiindex_2021_figaro_64.csv')\n",
    "\n",
    "# Load the 2021 multiindex figaro table\n",
    "df_2021 = pd.read_csv(file_path_2021, index_col=[0, 1], header=[0, 1])\n",
    "\n",
    "# Display the first few rows to verify structure\n",
    "print(df_2021.head())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Function to Apply Sector Mapping and Aggregate\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def apply_sector_mapping(df, sector_mapping):\n",
    "    \"\"\"\n",
    "    Rename and aggregate sectors in both rows and columns using the provided mapping.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Step 1: Rename Row Index (Industries)\n",
    "    new_row_index = [(country, sector_mapping.get(sector, sector)) for country, sector in df.index]\n",
    "    df.index = pd.MultiIndex.from_tuples(new_row_index, names=['Country', 'Sector'])\n",
    "\n",
    "    # ✅ Step 2: Rename Column Index (Industries)\n",
    "    new_col_index = [(country, sector_mapping.get(sector, sector)) for country, sector in df.columns]\n",
    "    df.columns = pd.MultiIndex.from_tuples(new_col_index, names=['Country', 'Sector'])\n",
    "\n",
    "    # ✅ Step 3: Aggregate Mapped Sectors\n",
    "    df = df.groupby(level=['Country', 'Sector']).sum()  # Aggregate rows\n",
    "    df = df.groupby(level=['Country', 'Sector'], axis=1).sum()  # Aggregate columns\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Apply Sector Mapping to FIGARO Data\n",
    "# ---------------------------------------------------\n",
    "\n",
    "df_2021_mapped = apply_sector_mapping(df_2021, sector_mapping)\n",
    "\n",
    "# Display the first few rows to verify the aggregation worked\n",
    "print(df_2021_mapped.head())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Add Gross Output Row\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def add_gross_output_row(df):\n",
    "    gross_output = df.sum(axis=0)\n",
    "    gross_output.name = ('GO', 'GO')\n",
    "    df = pd.concat([df, pd.DataFrame(gross_output).T])\n",
    "    return df\n",
    "\n",
    "df_2021_mapped = add_gross_output_row(df_2021_mapped)\n",
    "\n",
    "# Ensure the row indices have the same named index structure as the columns\n",
    "df_2021_mapped.index.names = df_2021_mapped.columns.names\n",
    "\n",
    "# Display the row index names\n",
    "print(\"Row index names:\", df_2021_mapped.index.names)\n",
    "\n",
    "# Display the column index names\n",
    "print(\"Column index names:\", df_2021_mapped.columns.names)\n",
    "\n",
    "# Display the row indices\n",
    "display(df_2021_mapped.index)\n",
    "\n",
    "# Display the first few rows to verify the Gross Output row was added\n",
    "print(df_2021_mapped.tail())\n",
    "df_2021_mapped.to_csv('C:/Users/danie/Nextcloud/Coding/Masterthesis/notebooks/NB_exio3_figaro_gas/figaro_mapped_2021.csv')\n",
    "def merge_countries(df, countries_to_merge, target='FIGW1'):\n",
    "    \"\"\"\n",
    "    Relabels rows and columns so that any country in countries_to_merge is replaced by target.\n",
    "    Then groups by the MultiIndex to sum the duplicated entries.\n",
    "    \n",
    "    Assumes both rows and columns are MultiIndex with levels ['Country', 'Sector'].\n",
    "    \n",
    "    Parameters:\n",
    "      df: pd.DataFrame with MultiIndex for both rows and columns\n",
    "      countries_to_merge: list of country codes to merge (e.g., ['AR', 'SA'])\n",
    "      target: the target country code to absorb the values (default 'FIGW1')\n",
    "      \n",
    "    Returns:\n",
    "      A DataFrame with the specified countries merged into the target.\n",
    "    \"\"\"\n",
    "    # Save the original index names (should be ['Country', 'Sector'])\n",
    "    row_index_names = df.index.names\n",
    "    col_index_names = df.columns.names\n",
    "    \n",
    "    # --- Relabel row index: Replace countries in countries_to_merge with target\n",
    "    new_row_index = [\n",
    "        (target if country in countries_to_merge else country, sector)\n",
    "        for country, sector in df.index\n",
    "    ]\n",
    "    df.index = pd.MultiIndex.from_tuples(new_row_index, names=row_index_names)\n",
    "    \n",
    "    # --- Relabel column index: Replace countries in countries_to_merge with target\n",
    "    new_col_index = [\n",
    "        (target if country in countries_to_merge else country, sector)\n",
    "        for country, sector in df.columns\n",
    "    ]\n",
    "    df.columns = pd.MultiIndex.from_tuples(new_col_index, names=col_index_names)\n",
    "    \n",
    "    # --- Group by the MultiIndex levels to aggregate duplicate entries (summing over duplicates)\n",
    "    df = df.groupby(level=row_index_names).sum()\n",
    "    df = df.groupby(axis=1, level=col_index_names).sum()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "merged_df = merge_countries(df_2021_mapped, ['AR', 'SA'])\n",
    "display(merged_df)\n",
    "\n",
    "merged_df.to_csv('C:/Users/danie/Nextcloud/Coding/Masterthesis/notebooks/NB_exio3_figaro_gas/figaro_mapped_2021_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# ----- STEP 0: Extract the gross output row\n",
    "# The gross output row has both levels of the index equal to \"GO\"\n",
    "go_row = merged_df.loc[(\"GO\", \"GO\")]\n",
    "\n",
    "# ----- STEP 1: Build a dictionary for gross output for each supplier column\n",
    "# For each supplier column (e.g. (AT, A01)), retrieve its gross output from the GO row.\n",
    "gross_output = {}\n",
    "for col in merged_df.columns:\n",
    "    country, supplier_sector = col\n",
    "    if supplier_sector != \"GO\":  # Only for supplier columns\n",
    "        try:\n",
    "            # The gross output for column (country, supplier_sector) is in the GO row.\n",
    "            go_value = go_row[col]\n",
    "            gross_output[col] = go_value\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Gross output for supplier column {col} not found; defaulting to 1.\")\n",
    "            gross_output[col] = 1\n",
    "\n",
    "# ----- STEP 2: Create the interindustry block\n",
    "# Exclude rows and columns where the Sector is \"GO\"\n",
    "rows_mask = merged_df.index.get_level_values(\"Sector\") != \"GO\"\n",
    "cols_mask = merged_df.columns.get_level_values(\"Sector\") != \"GO\"\n",
    "interindustry_block = merged_df.loc[rows_mask, cols_mask]\n",
    "\n",
    "# ----- STEP 3: Compute the technical coefficients\n",
    "# For each supplier column, divide all its entries by its corresponding gross output.\n",
    "def normalize_column(col):\n",
    "    supplier_key = col.name  # a tuple (country, supplier_sector)\n",
    "    denominator = gross_output.get(supplier_key, 1)\n",
    "    return col / denominator\n",
    "\n",
    "tech_coeff = interindustry_block.apply(normalize_column, axis=0)\n",
    "\n",
    "# ----- STEP 4: Save or display the technical coefficients table\n",
    "tech_coeff.to_csv('technical_coefficients_from_merged.csv')\n",
    "print(\"Technical coefficients table saved to 'technical_coefficients_from_merged.csv'.\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# ----- STEP 0: Extract the gross output row (since it’s unique, with index (\"GO\",\"GO\"))\n",
    "go_row = merged_df.loc[(\"GO\", \"GO\")]\n",
    "\n",
    "# ----- STEP 1: Build a dictionary for gross output for each supplier column\n",
    "# For each supplier column (e.g. (AT, A01)), retrieve its gross output from the GO row.\n",
    "gross_output = {}\n",
    "for col in merged_df.columns:\n",
    "    country, supplier_sector = col\n",
    "    if supplier_sector != \"GO\":  # Only for supplier columns\n",
    "        try:\n",
    "            # Retrieve the gross output for this supplier column from the GO row.\n",
    "            go_value = go_row[col]\n",
    "            gross_output[col] = go_value\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Gross output for supplier column {col} not found; defaulting to 1.\")\n",
    "            gross_output[col] = 1\n",
    "\n",
    "# ----- STEP 2: Create the interindustry block by excluding rows and columns where Sector == \"GO\"\n",
    "rows_mask = merged_df.index.get_level_values(\"Sector\") != \"GO\"\n",
    "cols_mask = merged_df.columns.get_level_values(\"Sector\") != \"GO\"\n",
    "interindustry_block = merged_df.loc[rows_mask, cols_mask]\n",
    "\n",
    "# ----- STEP 3: Compute the technical coefficients\n",
    "def normalize_column(col):\n",
    "    supplier_key = col.name  # a tuple (country, supplier_sector)\n",
    "    denominator = gross_output.get(supplier_key, 1)\n",
    "    return col / denominator\n",
    "\n",
    "tech_coeff = interindustry_block.apply(normalize_column, axis=0)\n",
    "\n",
    "# ----- STEP 4: Duplicate B rows with new sector names \"B_gas\" and \"B_nongas\"\n",
    "# Select rows where Sector == \"B\"\n",
    "b_rows = tech_coeff.loc[tech_coeff.index.get_level_values(\"Sector\") == \"B\"].copy()\n",
    "\n",
    "# Create duplicates with new sector names\n",
    "def update_sector(index, new_label):\n",
    "    # index is a MultiIndex; we rebuild it with the second level replaced for rows where it is \"B\"\n",
    "    new_tuples = []\n",
    "    for country, sector in index:\n",
    "        if sector == \"B\":\n",
    "            new_tuples.append((country, new_label))\n",
    "        else:\n",
    "            new_tuples.append((country, sector))\n",
    "    return pd.MultiIndex.from_tuples(new_tuples, names=index.names)\n",
    "\n",
    "b_rows_gas = b_rows.copy()\n",
    "b_rows_nongas = b_rows.copy()\n",
    "b_rows_gas.index = update_sector(b_rows.index, \"B_gas\")\n",
    "b_rows_nongas.index = update_sector(b_rows.index, \"B_nongas\")\n",
    "\n",
    "# Remove the original B rows and append the duplicates\n",
    "non_b_rows = tech_coeff.loc[tech_coeff.index.get_level_values(\"Sector\") != \"B\"]\n",
    "tech_coeff_rows_modified = pd.concat([non_b_rows, b_rows_gas, b_rows_nongas]).sort_index()\n",
    "\n",
    "# ----- STEP 5: Duplicate B columns with new sector names \"B_gas\" and \"B_nongas\"\n",
    "# Columns are a MultiIndex. First, identify columns where the Sector level is \"B\".\n",
    "b_cols_mask = tech_coeff_rows_modified.columns.get_level_values(\"Sector\") == \"B\"\n",
    "b_cols = tech_coeff_rows_modified.columns[b_cols_mask]\n",
    "\n",
    "# Extract the B columns\n",
    "b_cols_df = tech_coeff_rows_modified.loc[:, b_cols].copy()\n",
    "\n",
    "# Create two copies with new column labels\n",
    "def update_column_labels(columns, new_label):\n",
    "    new_tuples = []\n",
    "    for country, sector in columns:\n",
    "        if sector == \"B\":\n",
    "            new_tuples.append((country, new_label))\n",
    "        else:\n",
    "            new_tuples.append((country, sector))\n",
    "    return pd.MultiIndex.from_tuples(new_tuples, names=columns.names)\n",
    "\n",
    "b_cols_gas = b_cols_df.copy()\n",
    "b_cols_nongas = b_cols_df.copy()\n",
    "b_cols_gas.columns = update_column_labels(b_cols_gas.columns, \"B_gas\")\n",
    "b_cols_nongas.columns = update_column_labels(b_cols_nongas.columns, \"B_nongas\")\n",
    "\n",
    "# Remove original B columns from the DataFrame\n",
    "non_b_cols_mask = tech_coeff_rows_modified.columns.get_level_values(\"Sector\") != \"B\"\n",
    "non_b_cols = tech_coeff_rows_modified.columns[non_b_cols_mask]\n",
    "tech_coeff_cols_modified = tech_coeff_rows_modified.loc[:, non_b_cols]\n",
    "\n",
    "# Concatenate the non-B columns with the new duplicates along axis=1\n",
    "final_df = pd.concat([tech_coeff_cols_modified, b_cols_gas, b_cols_nongas], axis=1)\n",
    "\n",
    "# Optionally, sort the columns (and rows) if desired:\n",
    "final_df = final_df.sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "# ----- STEP 6: Save the final modified table to CSV\n",
    "final_df.to_csv('technical_coefficients_modified.csv')\n",
    "print(\"Modified technical coefficients table saved to 'technical_coefficients_modified.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the technical coefficients and energy shares data\n",
    "technical_coefficients = pd.read_csv('technical_coefficients_modified.csv', index_col=[0, 1], header=[0, 1])\n",
    "energy_shares = pd.read_csv('C:/Users/danie/Nextcloud/Coding/Masterthesis/exiobase/energy_shares.csv', index_col=[0, 1], header=[0, 1])\n",
    "\n",
    "# Ensure the indices are sorted for consistent operations\n",
    "technical_coefficients.sort_index(axis=0, inplace=True)\n",
    "technical_coefficients.sort_index(axis=1, inplace=True)\n",
    "energy_shares.sort_index(axis=0, inplace=True)\n",
    "energy_shares.sort_index(axis=1, inplace=True)\n",
    "\n",
    "# Iterate over all countries and sectors, applying weights and handling missing values\n",
    "for country in energy_shares.index.get_level_values(0).unique():\n",
    "    for sector in energy_shares.columns.get_level_values(1).unique():\n",
    "        # Check if the index exists, otherwise set default values\n",
    "        gas_share = energy_shares.loc[(country, 'B_gas'), (country, sector)] if (country, 'B_gas') in energy_shares.index and (country, sector) in energy_shares.columns else 0\n",
    "        nongas_share = energy_shares.loc[(country, 'B_nongas'), (country, sector)] if (country, 'B_nongas') in energy_shares.index and (country, sector) in energy_shares.columns else 1\n",
    "\n",
    "        # Apply the shares if the indices exist in technical_coefficients\n",
    "        if (country, 'B_gas') in technical_coefficients.index and (country, sector) in technical_coefficients.columns:\n",
    "            technical_coefficients.loc[(country, 'B_gas'), (country, sector)] *= gas_share\n",
    "        if (country, 'B_nongas') in technical_coefficients.index and (country, sector) in technical_coefficients.columns:\n",
    "            technical_coefficients.loc[(country, 'B_nongas'), (country, sector)] *= nongas_share\n",
    "\n",
    "# Save the updated technical coefficients table\n",
    "technical_coefficients.to_csv('technical_coefficients_with_weights.csv')\n",
    "print(\"Updated technical coefficients table saved to 'technical_coefficients_with_weights.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
