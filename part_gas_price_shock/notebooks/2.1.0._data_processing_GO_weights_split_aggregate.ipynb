{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226237de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_index_to_multiindex(df):\n",
    "    \"\"\"\n",
    "    Split the index and columns of the DataFrame into a MultiIndex.\n",
    "    The index and columns are expected to have a structure like 'XX_sector_code'.\n",
    "    \"\"\"\n",
    "    def split_index(index):\n",
    "        return pd.MultiIndex.from_tuples([tuple(i.split('_', 1)) for i in index], names=['Country', 'Sector'])\n",
    "\n",
    "    df.index = split_index(df.index)\n",
    "    df.columns = split_index(df.columns)\n",
    "    return df\n",
    "\n",
    "def process_files_and_split_index(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all CSV files in the input folder, split the index and columns into a MultiIndex,\n",
    "    and save the new files in the specified output directory with a 'multiindex_' prefix.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "\n",
    "            df = pd.read_csv(file_path, index_col=0)\n",
    "            df = split_index_to_multiindex(df)\n",
    "\n",
    "            # Save the modified DataFrame to the output directory with 'multiindex_' prefix\n",
    "            output_file_path = os.path.join(output_dir, f'multiindex_{filename}')\n",
    "            df.to_csv(output_file_path)\n",
    "            print(f\"Processed and saved {filename} to {output_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_dir = 'C:/Users/danie/Nextcloud/Coding/Masterthesis/data/raw/figaro_tables'\n",
    "output_dir = 'C:/Users/danie/Nextcloud/Coding/Masterthesis/notebooks/NB_exio3_figaro_gas/figaro_multi_index'\n",
    "process_files_and_split_index(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for the 2021 multiindex figaro table\n",
    "file_path_2021 = os.path.join(output_dir, 'multiindex_2021_figaro_64.csv')\n",
    "\n",
    "# Load the 2021 multiindex figaro table\n",
    "df_2021 = pd.read_csv(file_path_2021, index_col=[0, 1], header=[0, 1])\n",
    "\n",
    "# Display the first few rows of the dataframe to verify\n",
    "print(df_2021.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f573c7b-04e0-4465-a3b7-c5082c7c7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 1. Sector Mapping (Renaming + Aggregation)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "sector_mapping = {\n",
    "    \"C10T12\": \"C10-12\",\n",
    "    \"C13T15\": \"C13-15\",\n",
    "    \"C25\": \"C25_33\", \"C33\": \"C25_33\",  # Aggregated\n",
    "    \"C28\": \"C28_32\", \"C32\": \"C28_32\",  # Aggregated\n",
    "    \"C31_32\": \"C31_32\",\n",
    "    \"E37T39\": \"E37-39\",\n",
    "    \"J58\": \"J\", \"J59_60\": \"J\", \"J61\": \"J\", \"J62_63\": \"J\",  # Aggregated\n",
    "    \"M69_70\": \"M_N\", \"M71\": \"M_N\", \"M72\": \"M_N\", \"M73\": \"M_N\", \"M74_75\": \"M_N\",\n",
    "    \"N77\": \"M_N\", \"N78\": \"M_N\", \"N79\": \"M_N\", \"N80T82\": \"M_N\",\n",
    "    \"Q86\": \"Q\", \"Q87_88\": \"Q\",\n",
    "    \"R90T92\": \"R_S\", \"R93\": \"R_S\", \"S94\": \"R_S\", \"S95\": \"R_S\", \"S96\": \"R_S\",\n",
    "    \"L\": \"L68\"\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Load FIGARO Data for 2021\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Define the file path for the 2021 multiindex figaro table\n",
    "file_path_2021 = os.path.join(output_dir, 'multiindex_2021_figaro_64.csv')\n",
    "\n",
    "# Load the 2021 multiindex figaro table\n",
    "df_2021 = pd.read_csv(file_path_2021, index_col=[0, 1], header=[0, 1])\n",
    "\n",
    "# Display the first few rows to verify structure\n",
    "print(df_2021.head())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Function to Apply Sector Mapping and Aggregate\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def apply_sector_mapping(df, sector_mapping):\n",
    "    \"\"\"\n",
    "    Rename and aggregate sectors in both rows and columns using the provided mapping.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Step 1: Rename Row Index (Industries)\n",
    "    new_row_index = [(country, sector_mapping.get(sector, sector)) for country, sector in df.index]\n",
    "    df.index = pd.MultiIndex.from_tuples(new_row_index, names=['Country', 'Sector'])\n",
    "\n",
    "    # ✅ Step 2: Rename Column Index (Industries)\n",
    "    new_col_index = [(country, sector_mapping.get(sector, sector)) for country, sector in df.columns]\n",
    "    df.columns = pd.MultiIndex.from_tuples(new_col_index, names=['Country', 'Sector'])\n",
    "\n",
    "    # ✅ Step 3: Aggregate Mapped Sectors\n",
    "    df = df.groupby(level=['Country', 'Sector']).sum()  # Aggregate rows\n",
    "    df = df.groupby(level=['Country', 'Sector'], axis=1).sum()  # Aggregate columns\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Apply Sector Mapping to FIGARO Data\n",
    "# ---------------------------------------------------\n",
    "\n",
    "df_2021_mapped = apply_sector_mapping(df_2021, sector_mapping)\n",
    "\n",
    "# Display the first few rows to verify the aggregation worked\n",
    "print(df_2021_mapped.head())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Add Gross Output Row\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def add_gross_output_row(df):\n",
    "    gross_output = df.sum(axis=0)\n",
    "    gross_output.name = ('GO', 'GO')\n",
    "    df = pd.concat([df, pd.DataFrame(gross_output).T])\n",
    "    return df\n",
    "\n",
    "df_2021_mapped = add_gross_output_row(df_2021_mapped)\n",
    "\n",
    "# Ensure the row indices have the same named index structure as the columns\n",
    "df_2021_mapped.index.names = df_2021_mapped.columns.names\n",
    "\n",
    "# Display the row index names\n",
    "print(\"Row index names:\", df_2021_mapped.index.names)\n",
    "\n",
    "# Display the column index names\n",
    "print(\"Column index names:\", df_2021_mapped.columns.names)\n",
    "\n",
    "# Display the row indices\n",
    "display(df_2021_mapped.index)\n",
    "\n",
    "# Display the first few rows to verify the Gross Output row was added\n",
    "print(df_2021_mapped.tail())\n",
    "df_2021_mapped.to_csv('C:/Users/danie/Nextcloud/Coding/Masterthesis/notebooks/NB_exio3_figaro_gas/figaro_mapped_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08107e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_countries(df, countries_to_merge, target='FIGW1'):\n",
    "    \"\"\"\n",
    "    Relabels rows and columns so that any country in countries_to_merge is replaced by target.\n",
    "    Then groups by the MultiIndex to sum the duplicated entries.\n",
    "    \n",
    "    Assumes both rows and columns are MultiIndex with levels ['Country', 'Sector'].\n",
    "    \n",
    "    Parameters:\n",
    "      df: pd.DataFrame with MultiIndex for both rows and columns\n",
    "      countries_to_merge: list of country codes to merge (e.g., ['AR', 'SA'])\n",
    "      target: the target country code to absorb the values (default 'FIGW1')\n",
    "      \n",
    "    Returns:\n",
    "      A DataFrame with the specified countries merged into the target.\n",
    "    \"\"\"\n",
    "    # Save the original index names (should be ['Country', 'Sector'])\n",
    "    row_index_names = df.index.names\n",
    "    col_index_names = df.columns.names\n",
    "    \n",
    "    # --- Relabel row index: Replace countries in countries_to_merge with target\n",
    "    new_row_index = [\n",
    "        (target if country in countries_to_merge else country, sector)\n",
    "        for country, sector in df.index\n",
    "    ]\n",
    "    df.index = pd.MultiIndex.from_tuples(new_row_index, names=row_index_names)\n",
    "    \n",
    "    # --- Relabel column index: Replace countries in countries_to_merge with target\n",
    "    new_col_index = [\n",
    "        (target if country in countries_to_merge else country, sector)\n",
    "        for country, sector in df.columns\n",
    "    ]\n",
    "    df.columns = pd.MultiIndex.from_tuples(new_col_index, names=col_index_names)\n",
    "    \n",
    "    # --- Group by the MultiIndex levels to aggregate duplicate entries (summing over duplicates)\n",
    "    df = df.groupby(level=row_index_names).sum()\n",
    "    df = df.groupby(axis=1, level=col_index_names).sum()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "merged_df = merge_countries(df_2021_mapped, ['AR', 'SA'])\n",
    "display(merged_df)\n",
    "\n",
    "merged_df.to_csv('C:/Users/danie/Nextcloud/Coding/Masterthesis/notebooks/NB_exio3_figaro_gas/figaro_mapped_2021_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c525bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- STEP 0: Extract the gross output row\n",
    "# The gross output row has both levels of the index equal to \"GO\"\n",
    "go_row = merged_df.loc[(\"GO\", \"GO\")]\n",
    "\n",
    "# ----- STEP 1: Build a dictionary for gross output for each supplier column\n",
    "# For each supplier column (e.g. (AT, A01)), retrieve its gross output from the GO row.\n",
    "gross_output = {}\n",
    "for col in merged_df.columns:\n",
    "    country, supplier_sector = col\n",
    "    if supplier_sector != \"GO\":  # Only for supplier columns\n",
    "        try:\n",
    "            # The gross output for column (country, supplier_sector) is in the GO row.\n",
    "            go_value = go_row[col]\n",
    "            gross_output[col] = go_value\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Gross output for supplier column {col} not found; defaulting to 1.\")\n",
    "            gross_output[col] = 1\n",
    "\n",
    "# ----- STEP 2: Create the interindustry block\n",
    "# Exclude rows and columns where the Sector is \"GO\"\n",
    "rows_mask = merged_df.index.get_level_values(\"Sector\") != \"GO\"\n",
    "cols_mask = merged_df.columns.get_level_values(\"Sector\") != \"GO\"\n",
    "interindustry_block = merged_df.loc[rows_mask, cols_mask]\n",
    "\n",
    "# ----- STEP 3: Compute the technical coefficients\n",
    "# For each supplier column, divide all its entries by its corresponding gross output.\n",
    "def normalize_column(col):\n",
    "    supplier_key = col.name  # a tuple (country, supplier_sector)\n",
    "    denominator = gross_output.get(supplier_key, 1)\n",
    "    return col / denominator\n",
    "\n",
    "tech_coeff = interindustry_block.apply(normalize_column, axis=0)\n",
    "\n",
    "# ----- STEP 4: Save or display the technical coefficients table\n",
    "tech_coeff.to_csv('technical_coefficients_from_merged.csv')\n",
    "print(\"Technical coefficients table saved to 'technical_coefficients_from_merged.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ----- STEP 0: Extract the gross output row (since it’s unique, with index (\"GO\",\"GO\"))\n",
    "go_row = merged_df.loc[(\"GO\", \"GO\")]\n",
    "\n",
    "# ----- STEP 1: Build a dictionary for gross output for each supplier column\n",
    "# For each supplier column (e.g. (AT, A01)), retrieve its gross output from the GO row.\n",
    "gross_output = {}\n",
    "for col in merged_df.columns:\n",
    "    country, supplier_sector = col\n",
    "    if supplier_sector != \"GO\":  # Only for supplier columns\n",
    "        try:\n",
    "            # Retrieve the gross output for this supplier column from the GO row.\n",
    "            go_value = go_row[col]\n",
    "            gross_output[col] = go_value\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Gross output for supplier column {col} not found; defaulting to 1.\")\n",
    "            gross_output[col] = 1\n",
    "\n",
    "# ----- STEP 2: Create the interindustry block by excluding rows and columns where Sector == \"GO\"\n",
    "rows_mask = merged_df.index.get_level_values(\"Sector\") != \"GO\"\n",
    "cols_mask = merged_df.columns.get_level_values(\"Sector\") != \"GO\"\n",
    "interindustry_block = merged_df.loc[rows_mask, cols_mask]\n",
    "\n",
    "# ----- STEP 3: Compute the technical coefficients\n",
    "def normalize_column(col):\n",
    "    supplier_key = col.name  # a tuple (country, supplier_sector)\n",
    "    denominator = gross_output.get(supplier_key, 1)\n",
    "    return col / denominator\n",
    "\n",
    "tech_coeff = interindustry_block.apply(normalize_column, axis=0)\n",
    "\n",
    "# ----- STEP 4: Duplicate B rows with new sector names \"B_gas\" and \"B_nongas\"\n",
    "# Select rows where Sector == \"B\"\n",
    "b_rows = tech_coeff.loc[tech_coeff.index.get_level_values(\"Sector\") == \"B\"].copy()\n",
    "\n",
    "# Create duplicates with new sector names\n",
    "def update_sector(index, new_label):\n",
    "    # index is a MultiIndex; we rebuild it with the second level replaced for rows where it is \"B\"\n",
    "    new_tuples = []\n",
    "    for country, sector in index:\n",
    "        if sector == \"B\":\n",
    "            new_tuples.append((country, new_label))\n",
    "        else:\n",
    "            new_tuples.append((country, sector))\n",
    "    return pd.MultiIndex.from_tuples(new_tuples, names=index.names)\n",
    "\n",
    "b_rows_gas = b_rows.copy()\n",
    "b_rows_nongas = b_rows.copy()\n",
    "b_rows_gas.index = update_sector(b_rows.index, \"B_gas\")\n",
    "b_rows_nongas.index = update_sector(b_rows.index, \"B_nongas\")\n",
    "\n",
    "# Remove the original B rows and append the duplicates\n",
    "non_b_rows = tech_coeff.loc[tech_coeff.index.get_level_values(\"Sector\") != \"B\"]\n",
    "tech_coeff_rows_modified = pd.concat([non_b_rows, b_rows_gas, b_rows_nongas]).sort_index()\n",
    "\n",
    "# ----- STEP 5: Duplicate B columns with new sector names \"B_gas\" and \"B_nongas\"\n",
    "# Columns are a MultiIndex. First, identify columns where the Sector level is \"B\".\n",
    "b_cols_mask = tech_coeff_rows_modified.columns.get_level_values(\"Sector\") == \"B\"\n",
    "b_cols = tech_coeff_rows_modified.columns[b_cols_mask]\n",
    "\n",
    "# Extract the B columns\n",
    "b_cols_df = tech_coeff_rows_modified.loc[:, b_cols].copy()\n",
    "\n",
    "# Create two copies with new column labels\n",
    "def update_column_labels(columns, new_label):\n",
    "    new_tuples = []\n",
    "    for country, sector in columns:\n",
    "        if sector == \"B\":\n",
    "            new_tuples.append((country, new_label))\n",
    "        else:\n",
    "            new_tuples.append((country, sector))\n",
    "    return pd.MultiIndex.from_tuples(new_tuples, names=columns.names)\n",
    "\n",
    "b_cols_gas = b_cols_df.copy()\n",
    "b_cols_nongas = b_cols_df.copy()\n",
    "b_cols_gas.columns = update_column_labels(b_cols_gas.columns, \"B_gas\")\n",
    "b_cols_nongas.columns = update_column_labels(b_cols_nongas.columns, \"B_nongas\")\n",
    "\n",
    "# Remove original B columns from the DataFrame\n",
    "non_b_cols_mask = tech_coeff_rows_modified.columns.get_level_values(\"Sector\") != \"B\"\n",
    "non_b_cols = tech_coeff_rows_modified.columns[non_b_cols_mask]\n",
    "tech_coeff_cols_modified = tech_coeff_rows_modified.loc[:, non_b_cols]\n",
    "\n",
    "# Concatenate the non-B columns with the new duplicates along axis=1\n",
    "final_df = pd.concat([tech_coeff_cols_modified, b_cols_gas, b_cols_nongas], axis=1)\n",
    "\n",
    "# Optionally, sort the columns (and rows) if desired:\n",
    "final_df = final_df.sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "# ----- STEP 6: Save the final modified table to CSV\n",
    "final_df.to_csv('technical_coefficients_modified.csv')\n",
    "print(\"Modified technical coefficients table saved to 'technical_coefficients_modified.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f18bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
